{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.hiearchy_simple_ppo_env import ParallelEnv\n",
    "from utils.ppo_model import HiearchyModel as MyModel\n",
    "from utils.consts import (\n",
    "    MAX_NUM_STORES_LOADS,\n",
    "    MAX_NUM_LOOPS,\n",
    "    MAX_NUM_LOAD_STORE_DIM\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the environement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 19.58it/s]\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    'len_trajectory': 64,\n",
    "    'ppo_batch_size': 64,\n",
    "    'steps':10000,\n",
    "    'ppo_epochs':4,\n",
    "    'logs':True,\n",
    "    'entropy_coef':0.01,\n",
    "    'lr':0.001,\n",
    "    'truncate':5,\n",
    "    'json_file':\"generated_data/bigger_input_nn_(32x230x230x3)operations.json\",\n",
    "}\n",
    "\n",
    "env = ParallelEnv(\n",
    "    json_file=CONFIG[\"json_file\"],\n",
    "    num_env=1,\n",
    "    truncate=CONFIG[\"truncate\"],\n",
    "    reset_repeat=1,\n",
    "    step_repeat=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim: 411\n"
     ]
    }
   ],
   "source": [
    "# Define the model:\n",
    "input_dim = MAX_NUM_LOOPS + MAX_NUM_LOOPS*MAX_NUM_LOAD_STORE_DIM*MAX_NUM_STORES_LOADS + MAX_NUM_LOOPS*MAX_NUM_LOAD_STORE_DIM + 5 + \\\n",
    "    MAX_NUM_LOOPS*3*CONFIG[\"truncate\"]\n",
    "print('input_dim:', input_dim)\n",
    "\n",
    "model = MyModel(\n",
    "    input_dim=input_dim,\n",
    "    num_loops=MAX_NUM_LOOPS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_state, batch_obs = env.reset()\n",
    "obs = torch.cat(batch_obs).to(device)\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        action_index, action_log_p, values, entropy = model.sample(obs)\n",
    "    \n",
    "\n",
    "    batch_next_obs, batch_reward, batch_terminated, batch_truncated, batch_next_state, batch_final_state = env.step(batch_state, action_index, model)\n",
    "    \n",
    "    # print(batch_next_state[0].actions)\n",
    "\n",
    "    for i in range(env.num_env):\n",
    "        done     = batch_terminated[i] or batch_truncated[i]\n",
    "        final_state = batch_final_state[i]\n",
    "        # print(done)\n",
    "        if done:\n",
    "            speedup_metric = final_state.root_exec_time /  final_state.exec_time\n",
    "            print('-'*70)\n",
    "            print(final_state.operation_id)\n",
    "            print('speedup:', speedup_metric)\n",
    "            print('-'*70)                \n",
    "\n",
    "    batch_state = batch_next_state\n",
    "    obs = torch.cat(batch_next_obs).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(\n",
    "    input_dim=input_dim,\n",
    "    num_loops=MAX_NUM_LOOPS\n",
    ")\n",
    "\n",
    "# model.load_state_dict(torch.load('models/demo_model_bigger_nn.pt'))\n",
    "model.load_state_dict(torch.load('models/demo_ppo_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_operations = [\n",
    "    (1, 'linalg.conv_2d_nchw_fchw {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%0, %1 : tensor<32x3x230x230xf32>, tensor<64x3x7x7xf32>) outs(%12 : tensor<32x64x112x112xf32>) -> tensor<32x64x112x112xf32>'),\n",
    "    (4, 'linalg.conv_2d_nchw_fchw {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%18, %3 : tensor<32x64x56x56xf32>, tensor<16x64x5x5xf32>) outs(%20 : tensor<32x16x52x52xf32>) -> tensor<32x16x52x52xf32>'),\n",
    "    (15, 'linalg.matmul ins(%39, %41 : tensor<32x84xf32>, tensor<84x10xf32>) outs(%43 : tensor<32x10xf32>) -> tensor<32x10xf32>'),\n",
    "    (11, 'linalg.matmul ins(%32, %34 : tensor<32x120xf32>, tensor<120x84xf32>) outs(%36 : tensor<32x84xf32>) -> tensor<32x84xf32>'),\n",
    "    (0, 'linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%2 : tensor<64xf32>) outs(%11 : tensor<32x64x112x112xf32>) {\\n^bb0(%in: f32, %out: f32):\\n  linalg.yield %in : f32\\n} -> tensor<32x64x112x112xf32>'),\n",
    "    (2, 'linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%13 : tensor<32x64x112x112xf32>) outs(%11 : tensor<32x64x112x112xf32>) {\\n^bb0(%in: f32, %out: f32):\\n  %cst_1 = arith.constant 0.000000e+00 : f32\\n  %46 = arith.cmpf ugt, %in, %cst_1 : f32\\n  %47 = arith.select %46, %in, %cst_1 : f32\\n  linalg.yield %47 : f32\\n} -> tensor<32x64x112x112xf32>'),\n",
    "    (3, 'linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%4 : tensor<16xf32>) outs(%19 : tensor<32x16x52x52xf32>) {\\n^bb0(%in: f32, %out: f32):\\n  linalg.yield %in : f32\\n} -> tensor<32x16x52x52xf32>'),\n",
    "    (6, 'linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d1, d0)>], iterator_types = [\"parallel\", \"parallel\"]} ins(%5 : tensor<120x10816xf32>) outs(%26 : tensor<10816x120xf32>) {\\n^bb0(%in: f32, %out: f32):\\n  linalg.yield %in : f32\\n} -> tensor<10816x120xf32>'),\n",
    "    (8, 'linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = [\"parallel\", \"parallel\"]} ins(%30, %6 : tensor<32x120xf32>, tensor<120xf32>) outs(%28 : tensor<32x120xf32>) {\\n^bb0(%in: f32, %in_1: f32, %out: f32):\\n  %46 = arith.addf %in, %in_1 : f32\\n  linalg.yield %46 : f32\\n} -> tensor<32x120xf32>'),\n",
    "    (9, 'linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = [\"parallel\", \"parallel\"]} ins(%31 : tensor<32x120xf32>) outs(%28 : tensor<32x120xf32>) {\\n^bb0(%in: f32, %out: f32):\\n  %cst_1 = arith.constant 0.000000e+00 : f32\\n  %46 = arith.cmpf ugt, %in, %cst_1 : f32\\n  %47 = arith.select %46, %in, %cst_1 : f32\\n  linalg.yield %47 : f32\\n} -> tensor<32x120xf32>'),\n",
    "    (10, 'linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d1, d0)>], iterator_types = [\"parallel\", \"parallel\"]} ins(%7 : tensor<84x120xf32>) outs(%33 : tensor<120x84xf32>) {\\n^bb0(%in: f32, %out: f32):\\n  linalg.yield %in : f32\\n} -> tensor<120x84xf32>'),\n",
    "    (12, 'linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = [\"parallel\", \"parallel\"]} ins(%37, %8 : tensor<32x84xf32>, tensor<84xf32>) outs(%35 : tensor<32x84xf32>) {\\n^bb0(%in: f32, %in_1: f32, %out: f32):\\n  %46 = arith.addf %in, %in_1 : f32\\n  linalg.yield %46 : f32\\n} -> tensor<32x84xf32>'),\n",
    "    (13, 'linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<32x84xf32>) outs(%35 : tensor<32x84xf32>) {\\n^bb0(%in: f32, %out: f32):\\n  %cst_1 = arith.constant 0.000000e+00 : f32\\n  %46 = arith.cmpf ugt, %in, %cst_1 : f32\\n  %47 = arith.select %46, %in, %cst_1 : f32\\n  linalg.yield %47 : f32\\n} -> tensor<32x84xf32>'),\n",
    "    (14, 'linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d1, d0)>], iterator_types = [\"parallel\", \"parallel\"]} ins(%9 : tensor<10x84xf32>) outs(%40 : tensor<84x10xf32>) {\\n^bb0(%in: f32, %out: f32):\\n  linalg.yield %in : f32\\n} -> tensor<84x10xf32>'),\n",
    "    (16, 'linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = [\"parallel\", \"parallel\"]} ins(%44, %10 : tensor<32x10xf32>, tensor<10xf32>) outs(%42 : tensor<32x10xf32>) {\\n^bb0(%in: f32, %in_1: f32, %out: f32):\\n  %46 = arith.addf %in, %in_1 : f32\\n  linalg.yield %46 : f32\\n} -> tensor<32x10xf32>')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, operation in benchmark_operations:\n",
    "for i in range(len(env.env.operations_files)):    \n",
    "    \n",
    "    print(f'Operation ({i}):', env.env.operations_files[i][0])\n",
    "    \n",
    "    # Reset the environement with the specific operation\n",
    "    state, obs = env.reset(i)\n",
    "    obs = torch.cat(obs).to(device)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Select the action using the model\n",
    "            action, action_log_p, values, entropy = model.sample(obs)\n",
    "\n",
    "        # Apply the action and get the next state\n",
    "        next_obs, reward, terminated, truncated, next_state, final_state = env.step(state, action, model)\n",
    "        \n",
    "        done = terminated[0] or truncated[0]\n",
    "        if done:\n",
    "            final_state = final_state[0]\n",
    "            speedup_metric = final_state.root_exec_time /  final_state.exec_time\n",
    "            print('Base execution time:', final_state.root_exec_time)\n",
    "            print('New execution time:', final_state.exec_time)\n",
    "            print('speedup:', speedup_metric)\n",
    "            break             \n",
    "\n",
    "        state = next_state\n",
    "        obs = torch.cat(next_obs).to(device)\n",
    "\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusion_utils.transforms import *\n",
    "from utils.observation_utils import *\n",
    "from data_generation.data_generation_from_model import transform_wrapper\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base execution time: 0.00132489 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New execution time: 2e-07 ms\n",
      "Speedup: 6624.45\n"
     ]
    }
   ],
   "source": [
    "operation = \"\"\"linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d1)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"], tag = \"operation_0\"} ins(%4 : tensor<16xf32>) outs(%19 : tensor<32x16x52x52xf32>) {\\n^bb0(%in: f32, %out: f32):\\n  linalg.yield %in : f32\\n} -> tensor<32x16x52x52xf32>\"\"\"\n",
    "\n",
    "code = transform_wrapper(operation)\n",
    "\n",
    "old_exec_time = evaluate_code(code)\n",
    "print('Base execution time:', old_exec_time / 1e9, 'ms')\n",
    "\n",
    "new_code = code\n",
    "new_code = transform_dialect_TP(new_code, 'operation_0', [4, 4, 0, 0])\n",
    "new_code = transform_dialect_tile(new_code, 'operation_0', [2, 16, 4, 4])\n",
    "new_code = transform_dialect_vectorise(new_code, 'operation_0')\n",
    "\n",
    "\n",
    "new_exec_time = evaluate_code(new_code)\n",
    "print('New execution time:', new_exec_time / 1e9, 'ms')\n",
    "\n",
    "speedup = old_exec_time / new_exec_time\n",
    "print('Speedup:', speedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base execution time: 0.000108674 ms\n",
      "New execution time: 1.3e-07 ms\n",
      "Speedup: 835.9538461538461\n"
     ]
    }
   ],
   "source": [
    "operation = \"\"\"linalg.matmul {tag = \"operation_0\"} ins(%39, %41 : tensor<32x84xf32>, tensor<84x10xf32>) outs(%43 : tensor<32x10xf32>) -> tensor<32x10xf32>\"\"\"\n",
    "\n",
    "code = transform_wrapper(operation)\n",
    "\n",
    "old_exec_time = evaluate_code(code)\n",
    "print('Base execution time:', old_exec_time / 1e9, 'ms')\n",
    "\n",
    "new_code = code\n",
    "new_code = transform_dialect_TP(new_code, 'operation_0', [4, 5, 0])\n",
    "new_code = transform_dialect_interchange(new_code, 'operation_0', [1, 0, 2])\n",
    "new_code = transform_dialect_vectorise(new_code, 'operation_0')\n",
    "\n",
    "\n",
    "new_exec_time = evaluate_code(new_code)\n",
    "print('New execution time:', new_exec_time / 1e9, 'ms')\n",
    "\n",
    "speedup = old_exec_time / new_exec_time\n",
    "print('Speedup:', speedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base execution time: 17.573441457 ms\n",
      "New execution time: 2.590573458 ms\n",
      "Speedup: 6.78361055647008\n"
     ]
    }
   ],
   "source": [
    "operation = \"\"\"linalg.conv_2d_nchw_fchw {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>, tag = \"operation_0\"} ins(%0, %1 : tensor<32x3x230x230xf32>, tensor<64x3x7x7xf32>) outs(%12 : tensor<32x64x112x112xf32>) -> tensor<32x64x112x112xf32>\"\"\"\n",
    "\n",
    "code = transform_wrapper(operation)\n",
    "\n",
    "old_exec_time = evaluate_code_2(code)\n",
    "print('Base execution time:', old_exec_time / 1e9, 'ms')\n",
    "\n",
    "new_code = code\n",
    "\n",
    "new_code = transform_dialect_TP(new_code, 'operation_0', [4, 8, 0, 0, 0, 0, 0])\n",
    "new_code = transform_dialect_tile(new_code, 'operation_0', [2, 8, 0, 0, 3, 7, 7])\n",
    "new_code = transform_dialect_tile(new_code, 'operation_0', [2, 0, 1, 0, 0, 1, 0])\n",
    "new_code = apply_conv2d_decomposition(new_code, 'operation_0')\n",
    "new_code = transform_dialect_vectorise(new_code, 'operation_0')\n",
    "\n",
    "new_exec_time = evaluate_code_2(new_code)\n",
    "print('New execution time:', new_exec_time / 1e9, 'ms')\n",
    "\n",
    "speedup = old_exec_time / new_exec_time\n",
    "print('Speedup:', speedup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
